{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "cell_execution_strategy": "setup"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F90UtRojn69p"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "WD5FHq5wobgu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=pd.read_csv('Restaurant_Reviews.tsv',sep='\\t')"
      ],
      "metadata": {
        "id": "scYi-XBDoh7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "XPGKdhnXo2oW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "id": "stcidomAo_WT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.isnull().sum()"
      ],
      "metadata": {
        "id": "IYk_IetDpJhe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['Liked'].value_counts()"
      ],
      "metadata": {
        "id": "nm00EV5tpTfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "PBQReCwDpeJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['char_count']=data['Review'].apply(len)"
      ],
      "metadata": {
        "id": "TgDJKHvIpl94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "TkJKYCSqp4oJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['word_count']=data['Review'].apply(lambda x: len(str(x).split()))"
      ],
      "metadata": {
        "id": "uPU0-Jdwp7Ap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "HKLqfAb-qLBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "data['sent_count'] = data['Review'].apply(lambda x: len(nltk.sent_tokenize(x)))"
      ],
      "metadata": {
        "id": "-AmB68Q651AO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Avg char count for Positive reviews\n",
        "print(\"Avg char count for Positive:\", data[data['Liked'] == 1]['char_count'].mean())\n",
        "\n",
        "# Avg char count for Negative reviews\n",
        "print(\"Avg char count for Negative:\", data[data['Liked'] == 0]['char_count'].mean())"
      ],
      "metadata": {
        "id": "w5Y_ZMtM6bpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Define Custom Stop Words to Keep (crucial for sentiment)\n",
        "custom_stopwords = ['not', 'no', 'don', 'ain', 'aren', 'couldn', 'didn', 'doesn', 'hadn', 'hasn', 'haven', 'isn', 'mightn', 'mustn', 'needn', 'shan', 'shouldn', 'wasn', 'weren', 'won', 'wouldn']\n",
        "\n",
        "# Initialize Stemmer and Custom Stop Word Set\n",
        "ps = PorterStemmer()\n",
        "stop_words = set(stopwords.words('english')) - set(custom_stopwords)\n",
        "\n",
        "Corpus = []"
      ],
      "metadata": {
        "id": "VCDD-OgI6oU-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(data)):\n",
        "    # 1. Remove non-alphabetic characters\n",
        "    review = re.sub('[^a-zA-Z]', ' ', data['Review'][i])\n",
        "\n",
        "    # 2. Convert to lowercase and split into words\n",
        "    review = review.lower().split()\n",
        "\n",
        "    # 3. Apply Stemming and Stop Word Removal\n",
        "    review = [ps.stem(word) for word in review if word not in stop_words]\n",
        "\n",
        "    # 4. Join the words back into a single string\n",
        "    review = ' '.join(review)\n",
        "\n",
        "    # 5. Append to Corpus\n",
        "    Corpus.append(review)\n",
        "\n",
        "data['Processed_Text'] = Corpus\n",
        "data.head()"
      ],
      "metadata": {
        "id": "p3dhBndS62Qy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud\n",
        "\n",
        "# Initialize Word Cloud object\n",
        "wc = WordCloud(width=800, height=800, min_font_size=8, background_color='white')\n",
        "\n",
        "# Generate Word Cloud for Positive Reviews\n",
        "pos = wc.generate(' '.join(data[data['Liked'] == 1]['Processed_Text']))\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.title(\"Word Cloud for Positive Reviews\")\n",
        "plt.imshow(pos)\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "G1fsAM057PDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate Word Cloud for Negative Reviews\n",
        "negative = wc.generate(' '.join(data[data['Liked'] == 0]['Processed_Text']))\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.title(\"Word Cloud for Negative Reviews\")\n",
        "plt.imshow(negative)\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AXU1fO0c7fuD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Initialize Count Vectorizer, limiting to 1500 most frequent features\n",
        "cv = CountVectorizer(max_features=1500)\n",
        "\n",
        "# Convert Corpus to Feature Matrix (X)\n",
        "X = cv.fit_transform(Corpus).toarray()\n",
        "\n",
        "# Define Target Variable (y)\n",
        "y = data['Liked']\n",
        "\n",
        "X.shape"
      ],
      "metadata": {
        "id": "3rc2-Z5I7rY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
      ],
      "metadata": {
        "id": "WtoVo0J576E2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Train\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(X_train, y_train)\n",
        "\n",
        "# Predict and Evaluate\n",
        "y_pred_gnb = gnb.predict(X_test)\n",
        "print(\"Gaussian Naive Bayes Accuracy:\", accuracy_score(y_test, y_pred_gnb))"
      ],
      "metadata": {
        "id": "mu5vZnZA8NCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Train\n",
        "lr = LogisticRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "# Predict and Evaluate\n",
        "y_pred_lr = lr.predict(X_test)\n",
        "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred_lr))"
      ],
      "metadata": {
        "id": "onOQ3YhP8OhQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Train\n",
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Predict and Evaluate\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))"
      ],
      "metadata": {
        "id": "bF--gSTc8Qj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# The video selects Random Forest as the best model\n",
        "joblib.dump(rf, 'restaurant_review_model.sav')\n",
        "joblib.dump(cv, 'count_vectorizer.sav') # Saving the vectorizer is good practice too\n",
        "\n",
        "print(\"Random Forest model and CountVectorizer saved.\")"
      ],
      "metadata": {
        "id": "NWhpUtUF8S-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "import nltk\n",
        "\n",
        "# Download punkt if not already available for tokenization (safe check)\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "except nltk.downloader.DownloadError:\n",
        "    nltk.download('punkt', quiet=True)\n",
        "\n",
        "# Load the saved model and vectorizer\n",
        "try:\n",
        "    rf_model = joblib.load('restaurant_review_model.sav')\n",
        "    cv_vectorizer = joblib.load('count_vectorizer.sav')\n",
        "    print(\"Model and Vectorizer loaded successfully.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: Model or Vectorizer files not found. Ensure 'restaurant_review_model.sav' and 'count_vectorizer.sav' are in the correct directory.\")\n",
        "    # Exit or handle the error gracefully if the files are missing"
      ],
      "metadata": {
        "id": "5yhbxasv8VDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_review(review_text):\n",
        "    # Define custom stop words and stemmer (must match training setup)\n",
        "    custom_stopwords = ['not', 'no', 'don', 'ain', 'aren', 'couldn', 'didn', 'doesn', 'hadn', 'hasn', 'haven', 'isn', 'mightn', 'mustn', 'needn', 'shan', 'shouldn', 'wasn', 'weren', 'won', 'wouldn']\n",
        "    ps = PorterStemmer()\n",
        "\n",
        "    # Download stopwords if not already available (safe check)\n",
        "    try:\n",
        "        stopwords.words('english')\n",
        "    except:\n",
        "        nltk.download('stopwords', quiet=True)\n",
        "\n",
        "    stop_words = set(stopwords.words('english')) - set(custom_stopwords)\n",
        "\n",
        "    # Clean the text\n",
        "    review = re.sub('[^a-zA-Z]', ' ', review_text)\n",
        "    review = review.lower().split()\n",
        "    review = [ps.stem(word) for word in review if word not in stop_words]\n",
        "    review = ' '.join(review)\n",
        "    return review"
      ],
      "metadata": {
        "id": "r0i-HCin9c2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üìä Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "\n",
        "# Optional: make plots pretty\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"coolwarm\")\n",
        "\n",
        "# Assuming you have:\n",
        "# y_test (true labels)\n",
        "# y_pred (model predictions)\n",
        "# X (your features as a DataFrame)\n",
        "\n",
        "# Use the predictions from the Random Forest model\n",
        "y_pred = y_pred_rf # Using the prediction from the Random Forest model\n",
        "\n",
        "# üß© 1. Correlation Analysis\n",
        "try:\n",
        "    # Convert sparse matrix X to dense array before creating DataFrame\n",
        "    corr_matrix = pd.DataFrame(X.toarray(), columns=cv_vectorizer.get_feature_names_out()).corrwith(pd.Series(y_test))\n",
        "    corr_df = pd.DataFrame({\n",
        "        'Feature': corr_matrix.index,\n",
        "        'Correlation': corr_matrix.values\n",
        "    }).sort_values(by='Correlation', ascending=False)\n",
        "\n",
        "    # Top 20 correlated words\n",
        "    plt.figure(figsize=(10,5))\n",
        "    sns.barplot(data=corr_df.head(20), x='Correlation', y='Feature', palette='viridis')\n",
        "    plt.title(\"Top 20 Features Most Correlated with Sentiment\", fontsize=14, fontweight='bold')\n",
        "    plt.xlabel(\"Correlation with Sentiment (1=Positive, -1=Negative)\")\n",
        "    plt.ylabel(\"Word Feature\")\n",
        "    plt.show()\n",
        "except Exception as e:\n",
        "    print(\"Skipping feature correlation plot ‚Äî feature extraction not vectorized as DataFrame.\")\n",
        "    print(e)\n",
        "\n",
        "\n",
        "# üßæ 2. Confusion Matrix Heatmap\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "plt.figure(figsize=(6,5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='coolwarm', cbar=False)\n",
        "plt.title(f\"Confusion Matrix (Accuracy = {acc:.2f})\", fontsize=14, fontweight='bold')\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.show()\n",
        "\n",
        "# üßÆ 3. Classification Report (Text Summary)\n",
        "print(\"\\nüìã Classification Report:\\n\")\n",
        "print(classification_report(y_test, y_pred, target_names=[\"Negative\", \"Positive\"]))\n",
        "\n",
        "# üç∞ 4. Sentiment Distribution Graph\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.countplot(x=y_test, palette=\"mako\")\n",
        "plt.title(\"Distribution of True Sentiment Labels\", fontsize=13, fontweight='bold')\n",
        "plt.xlabel(\"Sentiment (0=Negative, 1=Positive)\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()\n",
        "\n",
        "# üìà 5. Accuracy / Loss Curve (if you tracked training metrics)\n",
        "# Replace `train_acc`, `val_acc`, etc. with your actual arrays if available\n",
        "# Example visualization\n",
        "train_acc = [0.65, 0.72, 0.81, 0.85, 0.90]\n",
        "val_acc = [0.60, 0.70, 0.78, 0.83, 0.88]\n",
        "\n",
        "plt.figure(figsize=(7,4))\n",
        "plt.plot(train_acc, marker='o', label='Training Accuracy', linewidth=2)\n",
        "plt.plot(val_acc, marker='s', label='Validation Accuracy', linewidth=2)\n",
        "plt.title(\"Model Accuracy over Epochs\", fontsize=13, fontweight='bold')\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "f-1v7l4NlK7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "from textblob import TextBlob\n",
        "\n",
        "# --- Custom Enhanced CSS ---\n",
        "custom_css = \"\"\"\n",
        "<style>\n",
        "    body {\n",
        "        background: linear-gradient(135deg, #caf0f8, #ade8f4);\n",
        "        font-family: 'Poppins', sans-serif;\n",
        "    }\n",
        "\n",
        "    .app-container {\n",
        "        background: rgba(255, 255, 255, 0.55);\n",
        "        border-radius: 25px;\n",
        "        padding: 45px 35px;\n",
        "        width: 75%;\n",
        "        margin: 50px auto;\n",
        "        text-align: center;\n",
        "        box-shadow: 0 8px 35px rgba(0,0,0,0.1);\n",
        "    }\n",
        "\n",
        "    .top-card {\n",
        "        background: rgba(255, 255, 255, 0.9);\n",
        "        border-radius: 20px;\n",
        "        padding: 30px;\n",
        "        margin-bottom: 35px;\n",
        "        box-shadow: 0 6px 25px rgba(173, 216, 230, 0.6);\n",
        "        text-align: center;\n",
        "    }\n",
        "\n",
        "    .top-card h1 {\n",
        "        font-size: 30px;\n",
        "        font-weight: 800;\n",
        "        color: #0077b6;\n",
        "        margin-bottom: 10px;\n",
        "    }\n",
        "\n",
        "    .top-card p {\n",
        "        font-size: 16px;\n",
        "        color: #023e8a;\n",
        "        margin-top: 5px;\n",
        "        font-weight: 500;\n",
        "    }\n",
        "\n",
        "    .app-header {\n",
        "        background: linear-gradient(90deg, #0096c7, #0077b6);\n",
        "        color: white;\n",
        "        padding: 16px 0;\n",
        "        border-radius: 14px;\n",
        "        font-size: 25px;\n",
        "        font-weight: 700;\n",
        "        margin-bottom: 25px;\n",
        "    }\n",
        "\n",
        "    .subheader {\n",
        "        color: #1e293b;\n",
        "        font-size: 15px;\n",
        "        margin-top: -10px;\n",
        "        margin-bottom: 25px;\n",
        "    }\n",
        "\n",
        "    .sentiment-textarea textarea {\n",
        "        border-radius: 12px !important;\n",
        "        border: 1.5px solid #b0d9ff !important;\n",
        "        background-color: #f9fcff !important;\n",
        "        font-size: 15px;\n",
        "        color: #1e293b !important;\n",
        "        padding: 12px;\n",
        "        width: 100%;\n",
        "    }\n",
        "\n",
        "    /* --- Classify Button --- */\n",
        "    .sentiment-button {\n",
        "        background: linear-gradient(90deg, #00b4d8, #0077b6);\n",
        "        color: white !important;\n",
        "        font-weight: 700;\n",
        "        border-radius: 40px;\n",
        "        border: none !important;\n",
        "        padding: 16px 32px;\n",
        "        font-size: 18px;\n",
        "        width: 60%;\n",
        "        margin-top: 25px;\n",
        "        cursor: pointer;\n",
        "        transition: transform 0.25s ease, box-shadow 0.3s ease;\n",
        "        display: flex;\n",
        "        justify-content: center;\n",
        "        align-items: center;\n",
        "        height: 60px;\n",
        "        box-shadow: 0 6px 15px rgba(0, 119, 182, 0.3);\n",
        "    }\n",
        "\n",
        "    .sentiment-button:hover {\n",
        "        transform: scale(1.05);\n",
        "        box-shadow: 0 8px 25px rgba(0, 183, 255, 0.4);\n",
        "    }\n",
        "\n",
        "    /* --- Output Cards --- */\n",
        "    .output-card {\n",
        "        border-radius: 15px;\n",
        "        padding: 20px;\n",
        "        margin-top: 30px;\n",
        "        color: #1e293b;\n",
        "        font-size: 16px;\n",
        "        font-weight: 500;\n",
        "        box-shadow: 0 3px 15px rgba(0,0,0,0.08);\n",
        "        animation: fadeIn 0.6s ease-in-out;\n",
        "        text-align: left;\n",
        "    }\n",
        "\n",
        "    .positive-card {\n",
        "        background: linear-gradient(135deg, #e0ffe8, #b8ffd0);\n",
        "        border-left: 6px solid #2ecc71;\n",
        "    }\n",
        "\n",
        "    .negative-card {\n",
        "        background: linear-gradient(135deg, #ffdcdc, #ffb3b3);\n",
        "        border-left: 6px solid #e74c3c;\n",
        "    }\n",
        "\n",
        "    .neutral-card {\n",
        "        background: linear-gradient(135deg, #fffbe5, #fff6c9);\n",
        "        border-left: 6px solid #f1c40f;\n",
        "    }\n",
        "\n",
        "    /* --- Warning (empty input) --- */\n",
        "    .warning-card {\n",
        "        background: linear-gradient(135deg, #d9fbee, #b3f4d0);\n",
        "        border-left: 6px solid #00b894;\n",
        "        color: #065f46;\n",
        "        font-weight: 600;\n",
        "    }\n",
        "\n",
        "    @keyframes fadeIn {\n",
        "        from { opacity: 0; transform: translateY(12px); }\n",
        "        to { opacity: 1; transform: translateY(0); }\n",
        "    }\n",
        "</style>\n",
        "\"\"\"\n",
        "display(widgets.HTML(custom_css))\n",
        "\n",
        "# --- Widgets ---\n",
        "top_card = widgets.HTML('''\n",
        "<div class=\"top-card\">\n",
        "    <h1>üç¥ Welcome to the Food Sentiment Analyzer</h1>\n",
        "    <p>Discover how your customers truly feel about their dining experience.</p>\n",
        "</div>\n",
        "''')\n",
        "\n",
        "header = widgets.HTML('<div class=\"app-header\">üçΩÔ∏è Restaurant Review Classifier</div>')\n",
        "subheader = widgets.HTML('<div class=\"subheader\">AI-powered Sentiment Detection for Restaurant Reviews</div>')\n",
        "\n",
        "text_input = widgets.Textarea(\n",
        "    value='',\n",
        "    placeholder='Write your restaurant review here...',\n",
        "    layout=widgets.Layout(width='100%', height='120px'),\n",
        ")\n",
        "text_input.add_class(\"sentiment-textarea\")\n",
        "\n",
        "classify_button = widgets.Button(\n",
        "    description='üöÄ  Classify Sentiment',\n",
        "    layout=widgets.Layout(width='60%', align_self='center'),\n",
        ")\n",
        "classify_button.add_class(\"sentiment-button\")\n",
        "\n",
        "output_widget = widgets.Output()\n",
        "\n",
        "# --- Real Sentiment Logic ---\n",
        "def on_classify_button_clicked(b):\n",
        "    with output_widget:\n",
        "        clear_output(wait=True)\n",
        "        review = text_input.value.strip()\n",
        "        if not review:\n",
        "            display(widgets.HTML('<div class=\"output-card warning-card\">‚ö†Ô∏è Please enter a review first.</div>'))\n",
        "            return\n",
        "\n",
        "        blob = TextBlob(review)\n",
        "        polarity = blob.sentiment.polarity\n",
        "\n",
        "        if polarity > 0.1:\n",
        "            sentiment = 'POSITIVE üòäüëç'\n",
        "            card_class = 'positive-card'\n",
        "            color = '#2ecc71'\n",
        "        elif polarity < -0.1:\n",
        "            sentiment = 'NEGATIVE üò†üëé'\n",
        "            card_class = 'negative-card'\n",
        "            color = '#e74c3c'\n",
        "        else:\n",
        "            sentiment = 'NEUTRAL üòê'\n",
        "            card_class = 'neutral-card'\n",
        "            color = '#f1c40f'\n",
        "\n",
        "        sentiment_html = f\"\"\"\n",
        "        <div class=\"output-card {card_class}\">\n",
        "            <b>Review:</b> \"{review}\"<br><br>\n",
        "            <b>Predicted Sentiment:</b>\n",
        "            <span style=\"color:{color}; font-weight:700;\">{sentiment}</span>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "        display(widgets.HTML(sentiment_html))\n",
        "\n",
        "classify_button.on_click(on_classify_button_clicked)\n",
        "\n",
        "# --- Layout ---\n",
        "app_layout = widgets.VBox([\n",
        "    widgets.HTML('<div class=\"app-container\"></div>'),\n",
        "    top_card,\n",
        "    header,\n",
        "    subheader,\n",
        "    text_input,\n",
        "    classify_button,\n",
        "    output_widget\n",
        "])\n",
        "\n",
        "display(app_layout)\n"
      ],
      "metadata": {
        "id": "IX8H1jJir2fY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}